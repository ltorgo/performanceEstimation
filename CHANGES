DEVELOPMENT VERSION

- show method of workflows changed to not truncate the parameters of learners. Now it always shows all parameters spread over different text lines.
- Calls to .loadedPackages replaced by calls to the base function .packages that does the same
- Changed the parallel computation backend. The package now is built upon the infra-structure of parallelMap
- Corrected a small typo on the example of the help page of mcEstimates
- Added a few new two-class metrics.
- Corrected serious mistakes (giving incorrect values) on some two-class metrics (thanks Kohji Muraoka!).
- Added a new parameter to functions rankWorkflows, topPerformers and topPerformer, which allows the user to specify which of the summary statistics shown in the summary, is to be used (defaults to "avg")
- Corrected a problem with the metric names in the results objects. They were not properly filled in when using user-supplied evaluator functions.
- Changed the way some functions where being called internally (suggestion of Andre Mikulec). The new version allows you to supply, for instance, a learner equal to "e1071::svm" thus avoiding having to load the e1071 package before running the experiments. 

VERSION 1.0.2 (2015-09-08)

- WFouput was removed from the framework. Now workflows should simply return a list with the information necessary for the calculation of the required performance metrics. Our provided evaluation functions (classificationMetrics and regressionMetrics) required some information from the result of the workflows (at least a component named "preds" containing a named vector of predicted values and another component named "trues" containing the corresponding vector of true values of the test cases). If you are using some of our provided standard workflows you do not need to worry about this because they return a list with such components. However, if using your own user-defined workflows and you want to use our evaluation functions then you need to worry abou this. In summary, if your code was using standard workflows and evaluation metrics provided by this package, then no changes should be needed to your code as a consequence of this removal of the class WFoutput. However, if that is not the case then you may need to carry out some small changes to your workflows or your evaluation functions.

- The removal of WFoutput had many changes in several functions namely: .scoresIts (experiments.R), runWorkflow (workflows.R) and classificationMetrics and regressionMetrics (evaluationMetrics.R). There was also a change in the EstimationResults class. All these changes have no impact in any code that was using the standard workflows provided by the package - they should work as before with no change necessary. Code using user-defined workflows will have an impact as well as user-defined evaluator functions.

- With the disappearance of WFoutput  also disappear the workflowInformation and workflowPredictions functions

- Functions getIterationInfo and getIterationPreds where renamed into getIterationsInfo and getIterationsPreds, respectively. They now have an additional functionality of allowing the user to obtain a list with the results of all iterations instead of only of a specific one, as before. Moreover, the results (either of a specific iteration or all of them) are of a different type. They use to be of class WFouput but now are simply lists, which is now the result of running any workflow.

- There were some problems in the timeseriesWF that were corrected

- The metrics parameter of the EstimationTask constructor is now optional and it defaults to all metrics of the selected evaluation function.

VERSION 1.0.1 (2015-06-17)

- EstimationTask class changed to include a parameter that specifies whether the training data is required for the evaluator function to calculate the metrics.
- Example of user-defined function in EstimationTask documentation was corrected.
- Documentation of the subset method of ComparisonResults objects was corrected to refer the parameter partial.
- Corrected bug on the way mcEstimates accessed the user suplied dataSplits
- The post-processing method that maximizes the utility of predictions for classification tasks was wrongly associated with the MetaCost work of Pedro Domingos. Although strongly related this was incorrect. Renamed everything to 'maxutil' and referred the work of Charles Elkan as the major reference on this approach.
- Some changes and additions to the package vignette

VERSION 1.0.0 (2014-12-02)

- Very radical change on the package introducing incompatibilities with 
  the version 0.x.y versions. A kind of fresh new re-start for the 
  package.
- Far too many changes to be written here. You are strongly advised to 
  check the included package vignette to check the new way the package 
  works. 

VERSION 0.1.1 (2014-03-11)

- corrections to Citation and minor stuff on package vignette
- corrected bug on subset method for class ComparisonResults
- corrected bug on topPerformers() function
- corrected but on workflowVariants() when using a benefit matrix